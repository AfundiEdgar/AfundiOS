# ============================================================================
# AOSB Backend Configuration Template
# ============================================================================
# Copy this file to .env and fill in your values
# This file should NOT be committed to version control
#
# Usage:
#   1. cp .env.example .env
#   2. Edit .env with your values
#   3. Run: python -m backend.config_validator
# ============================================================================

# ============================================================================
# Environment
# ============================================================================
# Options: local, development, staging, production
ENVIRONMENT=local

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# Select your LLM provider: openai, anthropic, cohere, aws_bedrock, or local
LLM_PROVIDER=openai

# Model name for the selected provider
# OpenAI examples: gpt-4o, gpt-4o-mini, gpt-3.5-turbo
# Anthropic examples: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# Cohere examples: command-r-plus, command-r, command
# AWS Bedrock examples: amazon.nova-lite-v1:0, amazon.nova-pro-v1:0, anthropic.claude-3-sonnet-20240229-v1:0
LLM_MODEL=gpt-4o-mini

# ============================================================================
# API Keys - Choose ONE provider based on LLM_PROVIDER
# ============================================================================

# For OpenAI (https://platform.openai.com/api-keys)
# Get your key: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# For Anthropic (https://console.anthropic.com/account/keys)
# Get your key: https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# For Cohere (https://dashboard.cohere.ai/api-keys)
# Get your key: https://dashboard.cohere.ai/api-keys
COHERE_API_KEY=your-cohere-api-key

# For AWS Bedrock
# Get your credentials: https://console.aws.amazon.com/iam/
# Region examples: us-east-1, us-west-2, eu-west-1
AWS_ACCESS_KEY_ID=your-aws-access-key-id
AWS_SECRET_ACCESS_KEY=your-aws-secret-access-key
AWS_REGION=us-east-1

# ============================================================================
# AWS Secrets Manager Configuration (Optional)
# ============================================================================
# Enable this for production deployments where credentials should not be in .env
# Requires: boto3 installed (pip install boto3)

# Set to "true" to use AWS Secrets Manager instead of .env for API keys
USE_SECRETS_MANAGER=false

# AWS region where your secrets are stored (default: us-east-1)
SECRETS_MANAGER_REGION=us-east-1

# Secret names for different LLM providers
# Example formats:
#   - prod/llm/openai
#   - prod/llm/anthropic
#   - dev/aws/bedrock
#   - prod/secrets/cohere

# OpenAI secret name (must contain 'api_key' field or be a plain string)
OPENAI_SECRET_NAME=

# Anthropic secret name (must contain 'api_key' field or be a plain string)
ANTHROPIC_SECRET_NAME=

# Cohere secret name (must contain 'api_key' field or be a plain string)
COHERE_SECRET_NAME=

# AWS Bedrock secret name (must contain 'access_key_id' and 'secret_access_key' fields)
AWS_BEDROCK_SECRET_NAME=
 
# Local LLM secret name (optional). If provided, secret may contain 'url' and/or 'api_key'
LOCAL_LLM_SECRET_NAME=

# ============================================================================
# Local LLM Configuration
# ============================================================================
# For self-hosted models using Ollama or similar
# Example: http://localhost:8000/v1 (for Ollama)
# Make sure your local LLM server is running before starting the app
LOCAL_LLM_URL=http://localhost:8000/v1

# ============================================================================
# LLM Parameters
# ============================================================================
# Temperature: 0.0 (deterministic) to 2.0 (creative)
# Default: 0.0 for factual responses
LLM_TEMPERATURE=0.0

# Maximum tokens in response
# Typical range: 512-4096 depending on use case
LLM_MAX_TOKENS=512

# ============================================================================
# Vector Store Configuration
# ============================================================================
# Type: chroma, pinecone, weaviate, or milvus
VECTOR_STORE_TYPE=chroma

# Local path for vector store (relative or absolute)
# This directory will be created if it doesn't exist
VECTOR_STORE_PATH=data/vector_store

# Embedding model for semantic search
# OpenAI models: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-small

# ============================================================================
# Encryption Configuration
# ============================================================================
# Enable encryption for stored data
ENCRYPTION_ENABLED=false

# Option 1: Provide a 32-byte hex key directly
# Generate: python -c "import secrets; print(secrets.token_hex(32))"
ENCRYPTION_KEY=

# Option 2: Derive encryption key from password
# If true, encryption key will be derived from password via key derivation function
ENCRYPTION_DERIVE_FROM_PASSWORD=false

# Encrypt document vectors/texts (slower, more private)
ENCRYPT_VECTOR_TEXTS=false

# Comma-separated list of metadata fields to encrypt
# Example: source,author,subject
ENCRYPT_METADATA_FIELDS=

# ============================================================================
# Metadata Database
# ============================================================================
# SQLite (default, no setup needed):
METADATA_DB_URL=sqlite:///data/metadata.db

# PostgreSQL (requires running PostgreSQL server):
# METADATA_DB_URL=postgresql://user:password@localhost:5432/aosb

# MySQL (requires running MySQL server):
# METADATA_DB_URL=mysql+pymysql://user:password@localhost:3306/aosb

# ============================================================================
# Memory Compaction & Maintenance
# ============================================================================
# Enable periodic compaction of vector store
MEMORY_COMPACTION_ENABLED=false

# Run compaction every N hours (0-24)
MEMORY_COMPACTION_INTERVAL_HOURS=24

# Keep documents from the last N days (0+ days)
MEMORY_COMPACTION_KEEP_DAYS=365

# Compaction strategy: deduplicate_exact or age_based
# - deduplicate_exact: Remove duplicate documents
# - age_based: Remove documents older than KEEP_DAYS
MEMORY_COMPACTION_STRATEGY=deduplicate_exact

# ============================================================================
# Daily Briefing Configuration
# ============================================================================
# Enable automatic daily briefing generation
DAILY_BRIEFING_ENABLED=false

# Generate briefing every N hours
DAILY_BRIEFING_INTERVAL_HOURS=24

# Include documents from the last N days in briefing
DAILY_BRIEFING_LOOKBACK_DAYS=1

# Briefing format: bullet_points, executive, or narrative
# - bullet_points: Quick bullet summary
# - executive: Formal executive summary
# - narrative: Detailed narrative summary
DAILY_BRIEFING_SUMMARY_STYLE=executive

# Maximum characters in briefing
DAILY_BRIEFING_MAX_CHARS=4000

# ============================================================================
# Helper commands
# ============================================================================
# Generate API keys:
#   OpenAI:     https://platform.openai.com/account/api-keys
#   Anthropic:  https://console.anthropic.com/account/keys
#   Cohere:     https://dashboard.cohere.ai/api-keys
#
# Validate configuration:
#   python -m backend.config_validator
#
# Check available models:
#   python -c "from backend.core.provider_factory import get_available_models; print(get_available_models())"
#
# Test LLM connection:
#   python -c "from backend.config import settings; print(settings.llm_provider, settings.llm_model)"
# ============================================================================
DAILY_BRIEFING_LOOKBACK_DAYS=1
DAILY_BRIEFING_SUMMARY_STYLE=executive
DAILY_BRIEFING_MAX_CHARS=4000

# Logging
LOG_LEVEL=info
